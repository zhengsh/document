# 网络配置

## 概述

容器网络是容器选择链接到其他容器，主机和外部网络得机制。容器得 runtime 提供了各种网络模式，每种模式都会产生不同得体验，例如，`Docker` 默认情况下可以容器配置一下网络：

* **none:** 将容器添加到一个容器专门的网络堆栈中，没有对外链接。
* **host:** 将容器i俺家到主机得网络堆栈中，没有隔离。
* **default bridge** 默认网络模式。每个容器可以通过 IP 地址互相连接。
* **自定义网桥** 用户自定义网桥，具有更多得灵活性、隔离性和其他便利功能。

## 什么是 CNI

CNI（Container Network Interface）是一个标准的，通用的接口，在容器平台，Docker Kubernetes, Mesos 容器网络解决方案 flannel， calico,  weave。只要提供一个标准的接口，就能为同样满足协议的所有容器平台提供网络共功能，而 CNI 正是这样的一个标准接口协议。

## Kubernetes 中的 CNI 插件

CNI 得初衷是创建一个框架。用于再配置或销毁容器时自动适配适当得网络配置和资源。插件负责为接口配置和管理 IP 地址。通常提供 IP管理，每个容器的 IP 分配、以及多主机链接相关的共嗯那个。容器运行时会调用网络插件，从而再容器启动时分配 IP 地址并且配置网络，并且再删除容器时再次调用他们清理这些资源。

运行时或协调器决定了哦那个其应该加入那个网络以及它需要调用那个插件。然后，插件会将接口添加到容器网络命名空间中，作为一个 veth 对的一侧。接着，他会再主机上进行更改，包括将 veth 的其他部分链接到网桥。再之后，他会通过调用单独的 IPAM （IP地址管理）插件来分配 IP 地址并设置路由。

再 Kubernetes 中， kubelet 可以再适当的时间调用它扎到它的插件，为通过 kubelet 启动的 pod 进行自动的网络配置。

Kubernetes 中可以选择的 CNI 插件如下：

* Flannel 
* Calico
* Canal
* Weave

## 什么是 Calico

Calico 为容器和虚拟机提供了安全的网络解决方案，并且经过了大规模的生产验证（在公有云和跨数千个集群节点中），可与 Kubernetes, OpenShift, Docker , Mesos， DC / OS  和 OpenStack 集成。

Calico 还可以提供网络安全规则的动态实施，适用 Calico 的简单策略语言，可以实现对容器，虚拟机工作负载和裸机主机断电之间通讯的细粒度控制。

##  安装网络插件 Calico

```shell
# 集群的 master 节点上执行
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml


# 一下内容表示安装成功
configmap/calico-config created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
serviceaccount/calico-node created
deployment.apps/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
```

确认安装成功

```shell
kubectl get pods --all-namespaces

# 等到所有状态为 Running, 注意时间可能比较久， 3-4分钟
NAMESPACE     NAME                                       READY   STATUS     RESTARTS   AGE
kube-system   calico-kube-controllers-578894d4cd-qshpj   1/1     Running    0          14m
kube-system   calico-node-hlcb2                          1/1     Running    0          68s
kube-system   calico-node-mrxkg                          0/1     Init:2/3   0          37s
kube-system   calico-node-sbzbt                          1/1     Running    0          46m
kube-system   coredns-7ff77c879f-5mwvk                   1/1     Running    0          14m
kube-system   coredns-7ff77c879f-wqzhq                   1/1     Running    0          14m
kube-system   etcd-k8s-master                            1/1     Running    1          23h
kube-system   kube-apiserver-k8s-master                  1/1     Running    1          23h
kube-system   kube-controller-manager-k8s-master         1/1     Running    1          23h
kube-system   kube-proxy-b5gnq                           1/1     Running    1          68s
kube-system   kube-proxy-mq9r5                           1/1     Running    1          37s
kube-system   kube-proxy-wnr7l                           1/1     Running    3          23h
kube-system   kube-scheduler-k8s-master                  1/1     Running    2          23h
```

## 解决 ImagePullBackOff

在使用 `watch kubectl get pods --all-namespaces` 命令观察 `Pods` 状态时出现 `ImagePullBackOff` 无法 Running 得情况，请尝试如下步骤：

* Master 种删除 Nodes : `kubectl delete nodes <name>`
* Slave 中重置配置：`kubeadm reset`
* Slave 重启计算机：`reboot`
* Slave 重新加入集群：`kubeadm join`