# Kafka 分区

### 关于 Kafka 分区
* 每一个分区都是一个有序、不可变的消息序列，后续新来的消息会源源不断、持续追加到分区的后面，这相当于一种结构化的提交日志（类似于Git的提交日志）

* 分区中的每一条消息都会被分配一个连续的id 值（即 offset）, 该值用于唯一标识分区中的每一条消息。

* 分区中的消息是存储到日志中的，而且同一个分区中的消息数据是按照发送顺序严格有序的。分区在逻辑上对应的日志，但生产者将消息写入分区中时，
实际上写到分区所对应的日志当中。而日志可以看作是一种逻辑上的概念，它对应于磁盘上的一个目录。一个日志文件由多个 Segment（段）来构成，每个
Segment 对应于一个索引文件与一个日志文件。

* 借助于分区我们可以 Kafka 的水平拓展。对于一台机器来说。无论是物理还是虚拟机，其运行能力总归是有上限的。当一台机器到达其能力上限时
就无法再拓展了，即垂直拓展能力总是受到硬件制约的。通过使用分区，我们可以将一个主题的消息分散到不同的 Kafka  Server（这里需要使用Kafka集群）
这样当机器能力不足时，我们只需要添加机器就可以了，在新的机器上创建新的分区，这样理论上可以实现无限的水平拓展能力。

* 分区还可以实现并行处理能力，向一个主题所发送的消息发送给消息的不同分区中，由多个分区进行接收和处理，

### Segment（段）
* 一个分区（partition）是由一系列有序、不可编的消息所构成。一个partition 中的消息数量可能会非常多，因此显然不能将所有消息都保存到一个文件当中
因此，类似于 log4j 的 rolling log， 当partition 中的消息数量增长到一定程度过后，消息文件就会进行切割，新的消息会写入到一个新的文件当中，
当新的文件增长到一定程度后，新的消息又会写入到另一个新的文件中，以此类推；这个一个个新的数据文件我们就称为segment(段)。

* 因此，partition 在物理上是由一个或者多个segment 所构成的。每个segment 中则保存了真实的消息数据。

### partition 与 segment 之间的关系
* 每一个partition 都相当于一个大型的文件被分配到多个大小相等的segment 数据文件中，每个segment 中的消息数量未必相等（这与消息大小有着密切的关系，
不同的消息所占据的磁盘空间显然是不一样的），这个特点使得老的 segment 很容易被删掉，有助于提升磁盘的效率。

* 每一个partition 只需要支持顺序读写即可，segment 文件的生命周期是由 Kafka Server 的配置参数所决定，比如说，server.properties 中参数项
log.retention.hours=168 就表示7天后会删除老的 segment 文件。

### 关于分区目录中的4个文件的含义与其作用
* 00000000000000000000.index: 它是一个segment 文件的索引文件，它接下来我们要介绍00000000000000000000.log数据文件是成对出现的，后缀
为.index 的就表示这个是一个索引文件。

* 00000000000000000000.log: 它的segment文件的数据文件, 用于存储实际的消息。该文件时二进制格式的。segment 文件的命名规则是 partition 
全局的第一个segment从0开始，后续每个segment 文件名为上一个segment 文件最有一条消息的offset 值。没有数字则用0来填充。

* 00000000000000000000.timeindex: 该文件时一个基于消息日期的索引文件，主要用途是在一些根据日期或事件来寻找消息的场景下使用，此外在基于
日期的日志 rolling 或是基于事件的日志保留策略等情况下也会使用。实际上，该文件是在Kafka 新版本中才增加的，老版本Kafka 没有该文件的。
它堆 *.index 文件的有益补充。*.index 文件是基于偏移量的索引嗯呢建，而*.timeindex 则是基于时间戳的索引文件。

* leader-epoch-checkpoint: 是leader 的缓存文件，实际上，它是与Kafka 的HW（High Water）与LEO（Log End Offset）相关的重要文件。 